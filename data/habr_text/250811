'250811 |@words привет хабра прошлый раз:4 рассмотреть:7 замечательный инструмент:7 vowpal:2 wabbit который:19 бывать полезный:2 случай:3 когда:4 приходиться обучаться выборка помещаться оперативный:4 память:4 напомнить что:8 особенность:2 данный:5 являться:3 позволять:3 строить один:6 очередь линейный модель слово:2 иметь хороший обобщать способность высокий качество алгоритм:3 достигаться счёт отбор генерация признак регуляризация прочий дополнительный:2 приём сегодня более:2 популярный:2 предназначить для:7 обработка:2 больший обьем дать:15 apache spark:8 быть:6 вдаваться подробность история возникновение:2 также:3 он:2 внутренний устройство сосредоточиться практический вещь этот:5 статья:2 базовый операция:7 основной:3 вещий можно:7 делать:4 spark':3 следующий:3 дробный:3 библиотека:2 mllib:3 машинный:3 обучение:3 graphx:3 граф:3 автор пост основное это:15 использовать как:10 тот:3 зачастую необходимый:6 держать кластер:3 время:2 очень:2 часто достаточно:2 wabbit' мануал много код рассматриваться понятие:3 философия про взять какой-нибудь датасет:14 практика:2 сразу:3 скажем нативный поддерживать:3 scala python:2 java пример:3 рассматривать:2 удобно работать:2 непосредственно:2 ipython notebook выгружать небольшой часть:2 обрабатывать например:6 пакет:2 pandas:4 получаться довольно удобный:2 связка итак:2 начать основный rdd:7 resilient distributed dataset:2 представлять себя:2 над:4 преобразование:3 два:4 тип соответственно весь:2 работа:5 структура заключаться последовательность действие:4 трансформация:3 результат:2 применение новый:3 правило:3 какой-либо образ преобразовывать элемент:11 вот:2 неполный самый:4 распространить:2 каждый:2 возвращать:7 map:2 function:6 применять:2 функция:8 filter вернуть истинный значение:3 distinct numtasks содержимый:2 уникальный исходный:2 стоить отметить:3 множество смысл:2 понятный название union otherdataset:3 intersection cartesian всевозможный пара:2 где принадлежать датасету-аргументудействие применяться:2 тогда материализовать сохранить диск либо:3 вывести консоль список:2 saveastextfile path:3 сохранять текстовый файл hdfs:2 локальный:2 машина или любой другой файловый система полный посмотреть:2 документация:2 collect вид:2 массив:2 уже:3 мало применить:2 различный:3 фильтр:2 визуализация анализ средство take count количество reduce:4 знакомый кто знак mapreduce механизм следовать принимать вход аргумент должный обязательно коммутативный ассоциативный основа знать при:4 теперь немного заняться показать:2 загружать:2 они простой:2 вычисление:4 запуск:2 первое сделать:2 создать sparkcontext если говорить обьект:2 отвечать реализация низкоуровневый spark-shell создаваться автоматически доступный загрузка:2 путь программа помощь:3 parallelize:3 data:2 localdata:4 5,7,1,12,10,25:2 ourfirstrdd хранилище textfile:2 oursecondrdd some the cluster пункт важный:2 хранение spark'e тоже cache отчасти благодаря стать так закэшировать учёт доступность последний производить итеративный:2 тем избавиться io-overhead' особенно контекст большинство начинать градиентный метод заканчивать такой pagerankработа после мочь говориться выше несколько:2 for item:2 ourrdd:5 top:2 print:3 загрузить dataframe' import dataframe lambda split вообще видно настолько далёкий:2 наверное нет писать просто оставить упражнение читатель:2 многие писаться буквально строка напоследок лишь именно вычислимый максимальный минимальный наш легко:3 догадаться max min sql ключ:2 делаться сначала чтобы выделить пользоваться встроить вроде sortbykey countbykey join предлагаться ознакомиться самостоятельно вопрос написать комментарий подробно отдельно